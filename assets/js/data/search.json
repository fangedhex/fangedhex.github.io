[ { "title": "Stable Diffusion: Part 2", "url": "/posts/stable-diffusion-part-2/", "categories": "ai, stable-diffusion", "tags": "", "date": "2023-05-29 17:39:00 +0200", "snippet": "Welcome to a second part for Stable Diffusion where I give some advices I found or learnt to make better generated images.Default promptFor the prompt, I always start with what I give below, it’s a base that works very well for me.Positive(For a realistic image)((realistic, photorealistic, raw photo)), ((masterpiece)), (8k, high quality, ultra high res), (highly detailed:1.2)(For a painting image)((realistic painting style)), ((masterpiece)), (8k, high quality, ultra high res), (highly detailed:1.2)Negativelow res, ((bad anatomy)), (low quality, worst quality:1.4), (monochrome:1.1), (lowres:1.1), disfigured, poorly drawn face, mutation, mutated, (low quality, worst quality:1.4, multiple limbs, creepy face, weird face, more than 2 hand, more than 2 arms, more than 2 legs, more than 2 feet, merged limbs, weird face, distorded body, distorded face), (missing finger, extra digits, fewer digits), ((mutated hands and fingers)), text, signature, deformed, ugly, poorly drawn hands, blur, blurry, (bad eyes:1.2), (misfigured pupils:1.2)ModelsI tested a lot of models to find the one I like the most for different image types.My most used models so far AnythingV5 for anime like images. Dreamshaper for somewhat realistic images but still keeps a drawing like style. ChilloutMix for realistic images.Models that I like and use sometimes RevAnimated LyrielNegative embeddings ?!I know about the negative embeddings, but I don’t use them that often but I still try when I want to see if it can fixes an image I like.Making upscaled version of an image with more detailsOne thing I found out is that images upscaled using 4x-UltraSharp are still bad if you zoom in a lot but the problem is that I can’t make draw image more than 512x512 pixels without having an out of memory error.For that, I installed ControlNet with its models and a script named Ultimate SD Upscale. I use control net to keep the img2img near the original with lowered denoising (0.15 seems like a good value but I check everytimes with X/Y/Z plot script to see the best value) and ultimate sd upscale will cut down the image into 512x512 chunks and upscale with the help of 4x-UltraSharp and add details to the final image.Sources CivitAI : Model repository Tutorial on how to use Ultimate SD Upscale" }, { "title": "Having fun with Stable Diffusion", "url": "/posts/having-fun-with-stable-diffusion/", "categories": "ai, stable-diffusion", "tags": "", "date": "2023-04-13 15:22:00 +0200", "snippet": "I don’t post that often on my website because I didn’t have anything to write. But recently, I picked up Stable Diffusion to generate some images for the fun. I started with okay stuff and learn a lot about the prompts I can use to have almost perfect results.Let’s check results I got with Stable Diffusion after I learned a lot about it :Some of those images have still some defaults in them. Let’s me explain what I tried and what I use now.Easy DiffusionAs I have AMD GPU and on Windows, I tried to find a working repository of Stable Diffusion UI. I found Easy Diffusion that uses my CPU for rendering. I did have my fun with it but I tried to find quickly another solution because waiting 5 minutes per rendered image is a bit long.Automatic1111 “fork” for AMD GPUOne of the popular UI is Automatic1111 one which have a fork (soon to be integrated into it ?) which has the possibility to use my AMD GPU for rendering.My workflowFor positive prompt, depending on if I want, I use the keywords 4k, 8k and photorealistic with other positive parameters.For negative prompt, I always add as minimum (I think I can still improve it but work very well right now.) :low res, bad anatomy, (low quality, worst quality:1.4), (monochrome:1.1), (lowres:1.1), disfigured, poorly drawn face, mutation, mutatedI generate a new image until I found something I like even if it has flaws. Sometimes it’s very quick, sometimes I need to add more into the prompt.After that I send the image I like to extras then I use UltraSharp with x2 upscale to upscale the image a bit. And I send that upscaled image to inpainting so I can remove the flaws as much as possible.When it’s done, I send it again to extra to upscale it for x2 (so x4 in final) and I get my final image.Links Easy Diffusion Automatic1111 Installation Wiki Automatic1111 fork Model Database UltraSharp" }, { "title": "Moving to Klipper", "url": "/posts/moving-to-klipper/", "categories": "ender3, klipper, raspberrypi", "tags": "", "date": "2022-10-24 10:34:00 +0200", "snippet": "Recently, I did a maintenance of my 3d printer (Ender 3 Pro) and I wanted for a long time to try Klipper as I have a Raspberry Pi with OctoPrint on it.I wanted also to remove the USB cable I use to connect the pi and the printer main board : the thing is that I couldn’t use the TFT port of the motherboard because there was the touchscreen using it. For fixing all of that, I saw that Klipper can have a better web UI and also we can attach directly a touchscreen to the pi to control Klipper. This article is just a summarized of what I found (videos, text) on Internet and applied to my printer through trial and error.Installing KlipperOn the Raspberry PiI did the complicated way of backing up my current octopi then I installed a fresh Raspbian on the SD card.On the new installation, I used kiauh to install Klipper, Moonraker and Mainsail.I, then, copied this example config as I have a SKR Mini E3 V2.0 as main board.Building the firmware for the main boardIn SSH shell on Pi, write :cd ~/klippermake menuconfigI did setup the mainboard to my SKR Mini E3 V2.0 (on the example config, you have a small header explaining what to enter).It should open a menu (like below) and enter the same value (it will makes the firmware “listen” on the TFT port) : Then run :makeWhen it’s compiled, just copy the klipper.bin file from the pi to another sd card that you insert on the main board and boot it up : it gonna update and install the new firmware.ConfigurationMain board connection[mcu]serial: /dev/ttyAMA0baud: 250000restart_method: commandUsing vanilla lcd until KlipperScreen (I need a touchscreen)I copied the configuration example and removed everything except :####################################################################### 128x64 Full Graphic Creality CR10 / ENDER 3 stockdisplay####################################################################### This section is used for a Creality \"12864\" display with a single# ribbon cable between the display's EXP3 plug and the# micro-controller board's EXP1 connector.[display]lcd_type: st7920cs_pin: EXP1_7sclk_pin: EXP1_6sid_pin: EXP1_8encoder_pins: ^EXP1_5, ^EXP1_3click_pin: ^!EXP1_2[output_pin beeper]pin: EXP1_1BL Touch + Bed Mesh[bltouch]sensor_pin: PC2control_pin: PA1x_offset: -43.0y_offset: -13.0samples: 3[safe_z_home]home_xy_position: 117.5, 117.5 # (nozzle in middle of the bed)speed: 50z_hop: 10z_hop_speed: 5BL Touch’s Z offset is found and saved using Klipper building command.[bed_mesh]speed: 120horizontal_move_z: 5mesh_min: 15,15mesh_max: 188,191probe_count: 5,5algorithm: bicubicMesh max is calculated from the max bed size - probe offset (to avoid getting an error of out of bound). After that, just probe the bed once, and save it to default.Some useful macro for the slicer (based on Cura default for Ender 3 Pro)[gcode_macro START_PRINT]gcode: {% set BED_TEMP = params.BED_TEMP|default(60)|float %} {% set EXTRUDER_TEMP = params.EXTRUDER_TEMP|default(210)|float %} # Use absolute coordinates G90 # Wait for bed to reach temperature M190 S{BED_TEMP} # Home the printer G28 # Set and wait for nozzle to reach temperature M109 S{EXTRUDER_TEMP} # Start macro for cleaning up the nozzle CLEAN_NOZZLE[gcode_macro CLEAN_NOZZLE]gcode: G1 Z2.0 F3000 ; Move Z Axis up little to prevent scratching of Heat Bed G1 X0.1 Y20 Z0.3 F5000.0 ; Move to start position G1 X0.1 Y200.0 Z0.3 F1500.0 E15 ; Draw the first line G1 X0.4 Y200.0 Z0.3 F5000.0 ; Move to side a little G1 X0.4 Y20 Z0.3 F1500.0 E30 ; Draw the second line G92 E0 ; Reset Extruder G1 Z2.0 F3000 ; Move Z Axis up little to prevent scratching of Heat Bed G1 X5 Y20 Z0.3 F5000.0 ; Move over to prevent blob squish[gcode_macro END_PRINT]gcode: # Turn off bed, extruder, and fan M140 S0 M104 S0 M106 S0 # Move nozzle away from print while retracting G91 G1 X-2 Y-2 E-3 F300 # Raise nozzle by 10mm G1 Z10 F3000 G90 # Present the print G1 X0 Y235 F3000 # Disable steppers M84Misc# Pi Temperature[temperature_sensor pi]sensor_type: temperature_hostIncreasing the print speed for free (printer goes brrrrrrr)To make the printer goes as fast as it can be, with reduced artefact and no layer shifting, there is the feature named input shaping. With that test print, you find manually your printer resonance and also your max printer acceleration speed.My config goes like this :[input_shaper]shaper_freq_x: 38.4615shaper_freq_y: 48.5437shaper_type: 3hump_eiIt’s a pretty amazing feature as you can see your printer going faster while maintaining a good print quality.Next upgrades I plan to add (for Klipper) A BTT PI TFT Touchscreen Accelerometer to automate the resonance compensation" }, { "title": "Backup a raspberry pi", "url": "/posts/backup-a-raspberry-pi/", "categories": "raspberrypi, backup", "tags": "", "date": "2022-10-20 16:57:00 +0200", "snippet": "I wanted to backup my current raspberry pi sd card so I can install something else on it. And if it doesn’t work, I can come back to that backup.The thing is that if I back it up, the image will be the size of the sdcard so I need to shring it. Here is how I proceeded (it was very simple).To create my image file, I used Win32 Disk Imager to do just that. Put the path where to save the image Select the sdcard device Click on read and wait until it finish.After that I used PiShrink on my Ubuntu WSL (Windows Subsystem for Linux) to shrink it to the smallest size possible. Just type that in a linux console :pishrink -Zap {filename}My sdcard was shrinked from 64 GiB (full size) to 1 GiB" }, { "title": "LVM Cookbook", "url": "/posts/lvm-cookbook/", "categories": "linux, lvm", "tags": "", "date": "2022-08-21 10:43:00 +0200", "snippet": "Physical Volume (PV) Management# Create a PVpvcreate {partition} {partition} /dev/sda1 for example# View current PVspvdisplayVolume Group (VG) Management# Create a VGvgcreate {vg_name} {partition} {vg_name} Name of the VG you want to create {partition} Partition to add the VG# Extend a VG with a new PVvgextend {vg_name} {partition} {vg_name} Name of the VG you want to create {partition} Partition to add the VG# View current VGsvgdisplayLogical Volume (LV) Management# Create a LVlvcreate -L {size} {vg_name} -n {lv_name} {size} Size of the new Logical Volume Can be written in G, M, K or 100%FREE {vg_name} Volume Group in which we create the Logical Volume {lv_name} Name for the created Logical Volume# View current LVslvdisplayConcatenation# Resize LV to get the space remaining (sinc we extended the VG)lvresize -l +100%free {lv_path} {lv_path} Logical Volume path can be found with lvdisplay | grep Path Don’t forget to resize your filesystem (ext4, btrfs …)Mirror# Setup LV for Raid1lvconvert --type raid1 --mirrors 1 {lv_path} {lv_path} Logical Volume path can be found with lvdisplay | grep Path " }, { "title": "Linux Networking Configuration", "url": "/posts/linux-network-configuration/", "categories": "linux, networking", "tags": "", "date": "2022-08-17 16:45:00 +0200", "snippet": "Configure a static IPWe need to modify the network configuration file /etc/network/interfaces to add this :auto ens18iface ens18 inet static address 192.168.0.2 netmask 255.255.255.0 gateway 192.168.0.1Configure custom dns serversWe need to modify the network configuration file /etc/resolv.conf to add this :nameserver dns1nameserver dns2nameserver dns3" }, { "title": "Proxmox Setup", "url": "/posts/proxmox-setup/", "categories": "proxmox", "tags": "", "date": "2022-08-06 16:19:00 +0200", "snippet": "Proxmox SetupI use ESXi 6.5 on my Dell R620 server but I cannot upgrade it or install vCenter for some reason. Also on ESXi 6.5, I have hard time passing through components.On Proxmox, it is easier to passthrough with IOMMU and also add software like NUT that I’m going to do later.I have also multiple disks on it and wanted to manage it as one : there is an hardware raid controller on it but it is very slow and I tried upgrading it and it failed at boot. So I choose to use the software ZFS provided by Proxmox installer (Raid 7 or RaidZ3 in my case because I use old hard drives).Now that Proxmox is installed and my drives are managed as one, I setup pci passthrough for later. For that, I followed the Proxmox Wiki and added the iommu arguments at the end of the line of /etc/kernel/cmdline like this :root=ZFS=rpool/ROOT/pve-1 boot=zfs quiet intel_iommu=on iommu=ptAnd then I ran the command to update systemd-boot and rebooted the server :proxmox-boot-tool refreshrebootAs tweak I installed both Nag Buster and Dark Theme.Both are simple to do, just run their installer and done.Sources Proxmox PCI Passthrough Understanding ZFS Raid levels" } ]
